# .dpc_access - Example Firewall Rules

# Section 1: Define aliases for groups of context files.
[file_groups]
work = work_*.json
personal = personal.json, health.json
learning = learning_*.json

# Section 2: Define the public profile for the Federation Hub.
# This is the ONLY data the Hub will ever see.
[hub]
# Allow access to the 'name' and 'description' from personal.json
personal.json:profile.name = allow
personal.json:profile.description = allow
# Allow access to the names of all topics from all learning files
@learning:knowledge_map.topics.*.name = allow

# Section 3: Define access rules for the local AI assistant.
[ai_scope:work]
# In "work" mode, the AI can read all work files...
@work:* = allow
# ...but is explicitly denied access to personal files.
@personal:* = deny

[ai_scope:personal]
@personal:* = allow
@work:* = deny

# Section 4: Define access rules for peers.
[group:colleagues]
# Colleagues can see my work availability and skills.
work_main.json:availability = allow
work_main.json:skills.* = allow

[node:dpc-node-boris-xyz]
# My friend Alice can see my personal profile and learning progress.
personal.json:profile.* = allow
@learning:* = allow

# Section 5: Remote Inference Permissions (Compute Sharing)
# Control who can use your local AI models for remote inference
# NOTE: This does NOT share hardware access - only API access to run AI models on your device
[compute]
enabled = false
# Allow specific nodes to request inference on your local AI models
allow_nodes = dpc-node-alice-xyz
# Allow node groups to request inference
allow_groups = trusted_developers
# Restrict which models can be used (empty = all models allowed)
allowed_models = llama3.1:8b, llama3:70b

# Section 6: Device Context Sharing (device_context.json)
# Control what hardware/software info is shared with peers
# This is for discovery and compatibility checking, NOT for resource sharing

[device_sharing:basic]
# Share OS and dev tools only (no hardware specs)
device_context.json:software.os.* = allow
device_context.json:software.runtime.* = allow
device_context.json:software.dev_tools.* = allow
device_context.json:software.package_managers = allow
device_context.json:hardware.* = deny

[device_sharing:compute]
# Share GPU info for peers to discover compute capabilities
# Used together with [compute] section to enable remote inference
device_context.json:hardware.gpu.* = allow
device_context.json:hardware.memory.* = allow
device_context.json:hardware.cpu.cores_physical = allow
device_context.json:software.ai_models.* = allow

[node:dpc-node-alice-xyz]
# Alice can request remote inference (see [compute] section above)
# Share device context so she can see what models/GPU are available
device_context.json:hardware.gpu.* = allow
device_context.json:hardware.memory.ram_gb = allow
device_context.json:software.ai_models.* = allow

[group:trusted_developers]
# Share dev environment details but not hardware
device_context.json:software.* = allow
device_context.json:hardware.* = deny